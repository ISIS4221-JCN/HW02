\newpage

\section{Mourning Tweets}

El desarrollo y código fuente de esta sección de la tarea se encuentra en el cuaderno \texttt{HW02\_4.ipynb} adjunto.

\subsection{Mourning Lexicon}

\subsubsection{Procesamiento de los \textit{Tweets}}

Antes de realizar la construcción de los \textit{Lexicones} e implementar los modelos de clasificación se realizó un proceso estándar para \textit{tokenizar} los \textit{tweets}. Para esto se hizo un procesamiento especial pensado en lenguaje especifico que se utiliza en \textit{Twitter} y las particularidades de ruido que este medio conlleva. Para esto se realizaron los siguientes pasos:

\begin{itemize}
    \item Remover la puntuación de los \textit{Tweets}.
    
    \item \textit{Tokenizar} el \textit{dataset} con el \textit{tokenizador} (\texttt{TweetTokenizer}) de \texttt{nltk} especializado para este tipo de datos. Esta herramienta:
    \begin{itemize}
        \item Estandariza todas las palabras a minúsculas.
        
        \item Reduce la longitud de las palabras en caso de repetir letras.
        
        \item Remueven caracteres especiales de \textit{Twitter} y usuarios (\textit{@}).
    \end{itemize}
    
    \item Remover las \textit{stop\_words} utilizando el set de palabras de \texttt{nltk} para cada uno de los idiomas (inglés y español).
    
    \item Con los términos (\textit{tokens}) de los \textit{tweets} se construye un vocabulario (o \textit{dictionary}) para cada uno de los \textit{datasets} (inglés y español). 
    
    \item Filtrar términos poco comunes (aquellos que aparecen en menos de 5 \textit{tweets}) y muy comunes (aquellos que aparecen en más del 75\% del \textit{dataset}). Para esto se uso la función \texttt{filter\_extremes} de \texttt{Gensim}. 
    
\end{itemize}

\subsubsection{Construcción de lexicones}

Una vez se tienen definido el diccionario para los dos datasets, se construyen los lexicones estimando la probabilidad de que cada uno de los términos (\textit{tokens}) este en cada clase (luto o no luto). En este caso, la clase \textbf{luto \textit{(mourning)} se modela como la clase positiva} ($c = 1$) y la clase de \textbf{no luto \textit{(no mourning)} se modela como la clase negativa} ($c = 0$). \\

Para estimar dichas probabilidades, se utilizan los conceptos de verosimilitud  (\textit{likelihood}) y de verosimilitud escalada (\textit{scaled likelihood}). Las expresiones para dichas probabilidades son adaptadas de la referencia \cite{Potts2010SALT}, y se presentan a continuación:

\begin{equation}
    \mathbf{P(w|c=i)} = \frac{f(w,c=i)}{\sum_{w\in C} f(w,c=i)}
    \label{likelihood}
\end{equation} 

Al escalar esta probabilidadc condicional con las probabilidades \textit{a priori} de las palabras y las clases (utilizando el teorema de Bayes), se obtiene la siguiente probabilidad condicional:

\begin{equation}
    \mathbf{P(c=i|w)} = \frac{P(w|c=i) p(c=i)}{p(w)} = \frac{P(w|c=i)}{\sum_{c\in C} P(w|c=i)}
    \label{scaled_likelihood}
\end{equation} 

En \cite{Potts2010SALT}, sugieren trabajar con esta segunda probabilidad condicional pues un sentido más acorde. Dada la palabra, cual es la probabilidad que pertenezca a la clase. No obstante, para los dataset en cuestión se analizan ambas probabilidades.

\subsubsection{Resultados}
A partir de las expresiones (\ref{likelihood}) y (\ref{scaled_likelihood}), se calculan las probabilidades de cada termino para la clase mourning ($c=1$) en los dos datasets (inglés y español).

\begin{table}[H]
    \centering
    \caption{Resultado de los 15 términos con mayor probabilidad de aparecer en tweets de luto (\textit{mourning}) del \textit{dataset} en español (ES).}
    \label{tab:es_lexicons}
    \includegraphics[width=\textwidth]{doc/images/ES_Lexicons.png}
\end{table}

\begin{table}[H]
    \centering
    \caption{Resultado de los 15 términos con mayor probabilidad de aparecer en tweets de luto (\textit{mourning}) del \textit{dataset} en inglés (EN).}
    \label{tab:en_lexicons}
    \includegraphics[width=\textwidth]{doc/images/EN_Lexicons.png}
\end{table}

En los cuadros \ref{tab:es_lexicons} y \ref{tab:en_lexicons} se observan los 15 términos con mayor probabilidad de pertenecer a un \textit{tweet} de luto para el \textit{dataset} en español y en inglés, respectivamente. En ambos casos se presentan los resultados ordenados tanto por su \textit{likelihood} (probabilidad $P(w|c=1)$) como por \textit{scaled likelihood} (probabilidad $P(c=1|w)$). En general los resultados son bastante similares en ambos idiomas, especialmente si se mira solo su probabilidad sin escalar. \\

En este caso, y a pesar de no estar ordenados exactamente igual, se observan términos muy similares en ambos idiomas. Acrónimos de luto como \textit{qdep}, el emoticón de las manos orando (id 50) y palabras como condolencias, pena, paz y familia (\textit{rip, condolences, peace, family, sorry}) se encuentran en ambas listas. De igual forma, al organizar los términos únicamente por esta probabilidad, se encuentran también palabras asociadas a la pandemia como coronavirus, covid, 19 en ambos idiomas. No obstante, es evidente que estos términos se encuentran ahí por su alta frecuencia a lo largo de todos los \textit{tweets}. Esto se puede afirmar poque, aunque su probabilidad condicional de pertenecer a la clase de luto $P(w|c=1)$ es muy alta, también lo es su probabilidad de pertenecer a la clase de no luto $P(w|c=0)$, e incluso en algunos casos es mayor. \\

Por otro lado, si se observan los términos ordenados por la probabilidad escalada $P(c=1|w)$ se obtiene una lista de palabras poco comunes. Esto se debe a que al escalar por la probabilidad de la palabra (dividir entre $p(w)$), las palabras poco comunes obtienen un peso muy importante. De hecho, el set de palabras que se obtiene, tiene en todos los términos la misma probabilidad (1). Esto quiere decir que son palabras que solo aparecen en la clase de luto (\textit{mourning}), a pesar de que su ocurrencia es realmente baja. 

\begin{table}[H]
    \centering
    \caption{Resultado de los 15 emoticones con mayor probabilidad de aparecer en tweets de luto (\textit{mourning}) del \textit{dataset} en español (ES).}
    \label{tab:es_emojis}
    \includegraphics[width=\textwidth]{doc/images/ES_Emojis.png}
\end{table}

Ahora bien, algo similar a lo que ocurre con las palabras ocurre con los emoticones (véase cuadros \ref{tab:es_emojis} y \ref{tab:en_emojis}). Al mirar solo la lista ordenada por la probabilidad $P(w|c=1)$ se observan emoticones similares como: caritas tristes y llorando y corazones rotos y negros, en los \textit{datasets} de ambos idiomas. Adicionalmente, en ambos casos las manos orando encabezan la lista. No obstante, al ordenar por la probabilidad $P(c=1|w)$, se obtienen algunos emoticones poco comunes (como el guante de boxeo y el águila), cuya probabilidad es 1, pues solo aparecen en los \textit{tweets} de luto a pesar de su baja frecuencia. Sin embargo, empiezan a aparecer algunos otros con un sentido más relacionado al luto, como la paloma blanca, la cruz, un ángel y las flores. 

\begin{table}[H]
    \centering
    \caption{Resultado de los 15 emoticones con mayor probabilidad de aparecer en tweets de luto (\textit{mourning}) del \textit{dataset} en español (ES).}
    \label{tab:en_emojis}
    \includegraphics[width=\textwidth]{doc/images/EN_Emojis.png}
\end{table}

\subsection{Clasificadores}


\subsection{Análisis de importancia de características}