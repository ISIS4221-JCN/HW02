{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW02 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B-_Ey_ZnIdkg"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import nltk, os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import random, pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cMhJWQ5JIgBU"
   },
   "outputs": [],
   "source": [
    "# Setting necessary constants\n",
    "files = ['positive', 'negative']\n",
    "categories = ['books', 'dvd', 'kitchen', 'electronics']\n",
    "characters_to_remove = '!()#@~\"'\n",
    "pattern = \"[\" + characters_to_remove + \"]\"\n",
    "classifiers = ['NB', 'LR','DT', 'RF']\n",
    "datasets = ['books', 'dvd', 'electronics', 'kitchen', 'all']\n",
    "features = ['bow', 'bool-bow', 'lexicon']\n",
    "n_estimators = np.sort(random.sample(range(1, 1000), 50))\n",
    "parameters = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': ('auto', 'sqrt', 'log2'),\n",
    "}\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading SentiWordNet lexicon\n",
    "neg_score = {}\n",
    "pos_score = {}\n",
    "with open('./data/EN_Lexicons/SentiWordNet_3.0.0.txt') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                splitted = line.split('\\t')[:5]\n",
    "                pos = {splitted[-1].split('#')[0]: float(splitted[2])}\n",
    "                neg = {splitted[-1].split('#')[0]: float(splitted[3])}\n",
    "                neg_score.update(neg)\n",
    "                pos_score.update(pos)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading AFINN lexicon\n",
    "ANFII = {}\n",
    "with open('./data/EN_Lexicons/AFINN-111.txt') as file:\n",
    "    for line in file:\n",
    "        item = line.strip('\\n').split('\\t')\n",
    "        d = {item[0]: int(item[1])}\n",
    "        ANFII.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading WordStat lexicon \n",
    "word_stat_pos = []\n",
    "word_stat_neg = []\n",
    "neg_words = False\n",
    "pos_words = False\n",
    "with open('./data/EN_Lexicons/WordStat Sentiments.txt') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if line.strip('\\t').replace(' ', '_').replace('\\n', '') == 'NEGATIVE_WORDS':\n",
    "            neg_words = True\n",
    "        if neg_words:\n",
    "            word_stat_neg.append(line.strip('\\t').split(' ')[0].replace(' ','_').lower())\n",
    "        if line.strip('\\t').replace(' ', '_').replace('\\n', '') == 'POSITIVE_WORDS':\n",
    "            neg_words = False\n",
    "            pos_words = True\n",
    "        if pos_words:\n",
    "            word_stat_pos.append(line.strip('\\t').split(' ')[0].replace(' ','_').lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading senticnet5.py lexicon\n",
    "%run ./data/EN_Lexicons/senticnet5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZfCuTy1VH_9n"
   },
   "outputs": [],
   "source": [
    "def read_file(category, file):\n",
    "    \"\"\" Reads a review file and orders dictionary, documents and tags\n",
    "    \n",
    "    Args:\n",
    "        category (str): category to be read\n",
    "        file (str): file to be read\n",
    "    \n",
    "    Returns:\n",
    "        list: list containing the words found in the file\n",
    "        list: list containing one dictionary per review with words and associated frequency\n",
    "        list: list with the tag associated to each document\n",
    "    \"\"\"\n",
    "    \n",
    "    words = []\n",
    "    docs = []\n",
    "    tags = []\n",
    "    with open('./data/SA/'+category+'/'+file+'.review', encoding='ISO-8859-1') as file:\n",
    "        for line in file:\n",
    "            words_and_freq = re.sub(pattern, \"\", line.strip('\\n').strip('\\x1a')).split('label:')\n",
    "            if words_and_freq[-1] == 'positive':\n",
    "                tag = int(1)\n",
    "            else:\n",
    "                tag = int(0)\n",
    "            tags.append(tag)\n",
    "            words_and_freq = words_and_freq[0].split(' ')\n",
    "            d = {}\n",
    "            for term in words_and_freq[:-1]:\n",
    "                split = term.split(':')\n",
    "                words.append(split[0])\n",
    "                x = {split[0]:int(split[1])}\n",
    "                d.update(x)\n",
    "            docs.append(d)\n",
    "    return [words, docs, tags]\n",
    "\n",
    "def build_dataset(category):\n",
    "    \"\"\" Given a category returns the necessary data to build the dataset\n",
    "    \n",
    "    Args:\n",
    "        category (str): Category from which to build dataset\n",
    "        \n",
    "    Returns:\n",
    "        'numpy.ndarray': dictionay associated to the given category\n",
    "        list: one dictionary per review\n",
    "        list: tag per document\n",
    "        list: one dictionary per review in unlabeled file\n",
    "        list: tag per document in unlabeled file\n",
    "    \"\"\"\n",
    "    \n",
    "    dictionary = []\n",
    "    documents = []\n",
    "    tags = []\n",
    "    for file in files:\n",
    "        [words_temp, docs_temp, tags_temp] = read_file(category, file)\n",
    "        words_temp = np.unique(words_temp)\n",
    "        for term in zip(docs_temp, tags_temp):\n",
    "            documents.append(term[0])\n",
    "            tags.append(term[1])\n",
    "        for word in words_temp:\n",
    "            dictionary.append(word)\n",
    "    temp, unlabeled_docs, unlabeled_tags = read_file(category, 'unlabeled')\n",
    "    return [np.array(np.unique(dictionary),dtype='str'), documents, tags, unlabeled_docs, unlabeled_tags]\n",
    "  \n",
    "def purge_dataset(dictionary, documents):\n",
    "    \"\"\" Removes the words with unitary frequency\n",
    "    \n",
    "    Args:\n",
    "        dictionary ('numpy.ndarray'): dictionary to be purged\n",
    "        documents (list): base list to define word frequency\n",
    "        \n",
    "    Returns:\n",
    "        'numpy.ndarray': purged dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    freq = np.zeros(len(dictionary))\n",
    "    for i, word in enumerate(dictionary):\n",
    "        for doc in documents:\n",
    "            try:\n",
    "                freq[i] = freq[i] + doc[word]\n",
    "            except:\n",
    "                pass\n",
    "    to_remove = []\n",
    "    for i, occurence in enumerate(zip(dictionary, freq)):\n",
    "        if occurence[1] == 1:\n",
    "            to_remove.append(i)\n",
    "    dictionary = np.delete(dictionary, to_remove)\n",
    "    return dictionary\n",
    "\n",
    "def build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, file, boolean):\n",
    "    \"\"\" Given dictionary and document arrays builds the according BOW\n",
    "    \n",
    "    Args:\n",
    "        dictionary ('numpy.ndarray'): associated dictionary\n",
    "        documents (list): dictionary per review\n",
    "        tags (list): tag per review\n",
    "        unlabeled_docs (list): dictioray per ulabeled review\n",
    "        unlabeled_tags (list): tag per unlabeded review\n",
    "        file (str): name of the file (labeled or not)\n",
    "        boolean (str): type of BOW expected\n",
    "        \n",
    "    Returns:\n",
    "        'numpy.matrix': matrix with BOW and tag per document\n",
    "    \"\"\"\n",
    "    \n",
    "    if file == 'labeled':\n",
    "        m = np.zeros((len(dictionary) + 1, len(documents)), dtype = np.bool_ if boolean == 'bool' else np.int8)\n",
    "        for i, document in enumerate(documents):\n",
    "            for key in document.keys():\n",
    "                index = np.where(dictionary == key)[0]\n",
    "                if len(index) != 0:\n",
    "                    m[index[0],i] = True if boolean == 'bool' else document[key]\n",
    "            m[-1, i] = tags[i]\n",
    "    else:\n",
    "        m = np.zeros((len(dictionary) + 1, len(unlabeled_docs)), dtype = np.bool_ if boolean == 'bool' else np.int8)\n",
    "        for i, document in enumerate(unlabeled_docs):\n",
    "            for key in document.keys():\n",
    "                index = np.where(dictionary == key)[0]\n",
    "                if len(index) != 0:\n",
    "                    m[index[0],i] = True if boolean == 'bool' else document[key]\n",
    "            m[-1, i] = unlabeled_tags[i]\n",
    "    return m\n",
    "\n",
    "def set_values(pos_count, neg_count, polarity_last, pos_sum, neg_sum, ANFII_pos_count, ANFII_neg_count, \n",
    "                      ANFII_pos_score, ANFII_neg_score, stat_pos, stat_neg, polarity_senticnet, file):\n",
    "    \"\"\" Returns and array of values with the lexicon extracted features\n",
    "    \n",
    "    Args:\n",
    "        pos_count (int): count of positive words according to SentiWordNet\n",
    "        neg_count (int): count of negative words according to SentiWordNet\n",
    "        polarity_last (float): polarity of the last word according to SentiWordNet\n",
    "        pos_sum (float): sum of the polarity of the positive words according to SentiWordNet\n",
    "        neg_sum (float): sum of the polatiry of the negative words according to SentiWordNet\n",
    "        ANFII_pos_count (int): count of positive words according to ANFII\n",
    "        ANFII_neg_count (int): count of negative words according to ANFII\n",
    "        ANFII_pos_score (int): sum of positive words according to ANFII\n",
    "        ANFII_neg_score (int): sum of negative words according to ANFII\n",
    "        stat_pos (int): count of positive words according to statWord\n",
    "        stat_neg (int): count of negative words according to statWord\n",
    "        polarity_senticnet (float): Polarity of the words according to senticnet\n",
    "        file (str): Name of the file to set the tag\n",
    "        \n",
    "    Returns:\n",
    "        'nump.ndarray': Array with all parameters organized\n",
    "    \"\"\"\n",
    "    \n",
    "    if neg_count == 0:\n",
    "        div = 0\n",
    "    else:\n",
    "        div = pos_count/neg_count\n",
    "    if file == 'positive':\n",
    "        tag = 1\n",
    "    else:\n",
    "        tag = 0\n",
    "    return np.array([pos_count, neg_count, polarity_last, pos_sum, neg_sum, ANFII_pos_count, ANFII_neg_count, \n",
    "                      ANFII_pos_score, ANFII_neg_score, stat_pos, stat_neg, polarity_senticnet, tag])\n",
    "\n",
    "def create_lexicon_vector(doc, file):\n",
    "    \"\"\" Extracts lexicon based features from doc\n",
    "    \n",
    "    Args:\n",
    "        doc (dict): Dictionary with document from with to extract lexicon features\n",
    "        file (str): file from wich the document came from\n",
    "    \n",
    "    Retuns:\n",
    "        'numpy.ndarray': values to be appended in lexicon matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    neg_count = pos_count = neg_sum = pos_sum = 0\n",
    "    ANFII_pos_count = ANFII_neg_count = ANFII_pos_score = ANFII_neg_score = 0\n",
    "    stat_pos = stat_neg = polarity_senticnet = 0\n",
    "    last_word = True; word_in_lex = False\n",
    "    words = list(doc.keys())\n",
    "    polarity_last = 0\n",
    "    for word in reversed(words):\n",
    "        list_words = word.split('_')\n",
    "        for list_word in list_words:\n",
    "            if list_word in neg_score.keys():\n",
    "                if neg_score[list_word] > 0:\n",
    "                    neg_count += 1\n",
    "                    neg_sum += neg_score[list_word]\n",
    "                    word_in_lex = True\n",
    "                if pos_score[list_word] > 0:\n",
    "                    pos_count += 1\n",
    "                    pos_sum += pos_score[list_word]\n",
    "                    word_in_lex = True\n",
    "                if word_in_lex and last_word:\n",
    "                    polarity_last = (neg_score[list_word]*-1) + (pos_score[list_word])\n",
    "                    last_word = False\n",
    "            if list_word in ANFII.keys():\n",
    "                if ANFII[list_word] > 0:\n",
    "                    ANFII_pos_count += 1\n",
    "                    ANFII_pos_score += ANFII[list_word]\n",
    "                else:\n",
    "                    ANFII_neg_count += 1\n",
    "                    ANFII_neg_score += ANFII[list_word]\n",
    "            if list_word in word_stat_pos:\n",
    "                stat_pos += 1\n",
    "            elif list_word in word_stat_neg:\n",
    "                stat_neg += 1\n",
    "            if list_word in list(senticnet.keys()):\n",
    "                polarity_senticnet += float(senticnet[list_word][7])\n",
    "    return set_values(pos_count, neg_count, polarity_last, pos_sum, neg_sum, ANFII_pos_count, ANFII_neg_count, \n",
    "                      ANFII_pos_score, ANFII_neg_score, stat_pos, stat_neg, polarity_senticnet, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build bool and not-bool BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWl2sJGFhV1s",
    "outputId": "87ad74cd-2970-4642-b45d-04786118ed8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [53:36<00:00, 804.16s/it]   \n"
     ]
    }
   ],
   "source": [
    "# Creates bool BOW and non-bool BOW matrices for each category\n",
    "for cat in tqdm(categories):\n",
    "    [dictionary, documents, tags, unlabeled_docs, unlabeled_tags] = build_dataset(cat)\n",
    "    dictionary = purge_dataset(dictionary, documents)\n",
    "    np.save('./data/SA/'+cat+'/dictionary.npy', dictionary)\n",
    "    ans = build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'labeled', 'bool')\n",
    "    np.save('./data/SA/'+cat+'/bool-labeled.npy',ans)\n",
    "    ans = build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'unlabeled', 'not-bool')\n",
    "    np.save('./data/SA/'+cat+'/unlabeled.npy',ans)\n",
    "    ans = build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'labeled', 'not-bool')\n",
    "    np.save('./data/SA/'+cat+'/labeled.npy',ans)\n",
    "    ans = build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'unlabeled', 'bool')\n",
    "    np.save('./data/SA/'+cat+'/bool-unlabeled.npy',ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zX6jWMTPomF6",
    "outputId": "fb3f1a2a-313a-4d50-fb65-0cbb87661383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100801,)\n"
     ]
    }
   ],
   "source": [
    "# Creates dictionary for all categories together\n",
    "dictionary = np.concatenate((np.load('./data/SA/books/dictionary.npy'),\n",
    "                            np.load('./data/SA/dvd/dictionary.npy'),\n",
    "                            np.load('./data/SA/electronics/dictionary.npy'),\n",
    "                            np.load('./data/SA/kitchen/dictionary.npy')), axis = 0)\n",
    "dictionary = np.array(np.unique(dictionary),dtype='str')\n",
    "print(dictionary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "0eYYrMIS-eKW",
    "outputId": "87c241c4-4f9e-4f7a-fae0-c453e0a90b1d"
   },
   "outputs": [],
   "source": [
    "# Creates dictionary matrices for books category based on whole dictionary\n",
    "[dictionary1, documents, tags, unlabeled_docs, unlabeled_tags] = build_dataset('books')\n",
    "np.save('./data/SA/all/bool-labeled.npy', build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'labeled', 'bool'))\n",
    "np.save('./data/SA/all/bool-unlabeled.npy', build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'unlabeled', 'bool'))\n",
    "np.save('./data/SA/all/labeled.npy', build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'labeled', 'not-bool'))\n",
    "np.save('./data/SA/all/unlabeled.npy', build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'unlabeled', 'not-bool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ev0gH3baDEOw"
   },
   "outputs": [],
   "source": [
    "# Creates dictionary matrices for dvd category based on whole dictionary\n",
    "[dictionary1, documents, tags, unlabeled_docs, unlabeled_tags] = build_dataset('dvd')\n",
    "m = np.load('./data/SA/all/bool-labeled.npy')\n",
    "np.save('./data/SA/all/bool-labeled.npy', \n",
    "        np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'labeled', 'bool')), axis = 1))\n",
    "m = np.load('./data/SA/all/bool-unlabeled.npy')\n",
    "np.save('./data/SA/all/bool-unlabeled.npy',\n",
    "        np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'unlabeled', 'bool')), axis = 1))\n",
    "m = np.load('./data/SA/all/labeled.npy')\n",
    "np.save('./data/SA/all/labeled.npy',\n",
    "        np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'labeled', 'not-bool')), axis = 1))\n",
    "m = np.load('./data/SA/all/unlabeled.npy')\n",
    "np.save('./data/SA/all/unlabeled.npy', \n",
    "        np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'unlabeled', 'not-bool')), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OYMv45NWEPDz"
   },
   "outputs": [],
   "source": [
    "# Creates dictionary matrices for electronics category based on whole dictionary\n",
    "[dictionary1, documents, tags, unlabeled_docs, unlabeled_tags] = build_dataset('electronics')\n",
    "m = np.load('./data/SA/all/bool-labeled.npy')\n",
    "np.save('./data/SA/all/bool-labeled.npy', \n",
    "        np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'labeled', 'bool')), axis = 1))\n",
    "m = np.load('./data/SA/all/bool-unlabeled.npy')\n",
    "np.save('./data/SA/all/bool-unlabeled.npy',\n",
    "        np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'unlabeled', 'bool')), axis = 1))\n",
    "m = np.load('./data/SA/all/labeled.npy')\n",
    "np.save('./data/SA/all/labeled.npy',\n",
    "        np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'labeled', 'not-bool')), axis = 1))\n",
    "m = np.load('./data/SA/all/unlabeled.npy')\n",
    "np.save('./data/SA/all/unlabeled.npy', \n",
    "        np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'unlabeled', 'not-bool')), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KreTuVuXEQkj"
   },
   "outputs": [],
   "source": [
    "# Creates dictionary matrices for kitchen category based on whole dictionary\n",
    "[dictionary1, documents, tags, unlabeled_docs, unlabeled_tags] = build_dataset('kitchen')\n",
    "m = np.load('./data/SA/all/bool-labeled.npy')\n",
    "np.save('./data/SA/all/bool-labeled.npy', \n",
    "       np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'labeled', 'bool')), axis = 1))\n",
    "m = np.load('./data/SA/all/bool-unlabeled.npy')\n",
    "np.save('./data/SA/all/bool-unlabeled.npy',\n",
    "        np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'unlabeled', 'bool')), axis = 1))\n",
    "m = np.load('./data/SA/all/labeled.npy')\n",
    "np.save('./data/SA/all/labeled.npy',\n",
    "        np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'labeled', 'not-bool')), axis = 1))\n",
    "m = np.load('./data/SA/all/unlabeled.npy')\n",
    "np.save('./data/SA/all/unlabeled.npy', \n",
    "        np.concatenate((m, build_matrix(dictionary, documents, tags, unlabeled_docs, unlabeled_tags, 'unlabeled', 'not-bool')), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ojL6RdHbFRWa"
   },
   "outputs": [],
   "source": [
    "# Saves complete dictionary\n",
    "np.save('./data/SA/all/dictionary.npy', dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates lexicon matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [8:12:36<2:45:02, 9902.49s/it]"
     ]
    }
   ],
   "source": [
    "# Creates matrices with lexicon extracted features\n",
    "for cat in tqdm(['books', 'dvd', 'electronics', 'kitchen']):\n",
    "    m = np.zeros((1,13))\n",
    "    for file in ['positive', 'negative']:\n",
    "        words, docs, tags = read_file('books', file)\n",
    "        for doc in docs:\n",
    "            n = np.reshape(create_lexicon_vector(doc, file), (1,13))\n",
    "            m = np.append(m, n, axis=0)\n",
    "    m[~np.all(m == 0, axis=1)]\n",
    "    np.save('./data/SA/'+cat+'/lexicon-labeled.npy', np.transpose(m[1:,:]))\n",
    "    words, docs, tags = read_file('books', 'unlabeled')\n",
    "    m = np.zeros((1,13))\n",
    "    for doc in docs:\n",
    "        n = np.reshape(create_lexicon_vector(doc, file), (1,13))\n",
    "        m = np.append(m, n, axis=0)\n",
    "    m[~np.all(m == 0, axis=1)]\n",
    "    np.save('./data/SA/'+cat+'/lexicon-unlabeled.npy', np.transpose(m[1:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates matrices of lexicon extracted features for all categories together\n",
    "np.save('./data/SA/all/lexicon-labeled.npy', np.concatenate((np.load('./data/SA/books/lexicon-labeled.npy'),\n",
    "                                                             np.load('./data/SA/dvd/lexicon-labeled.npy'),\n",
    "                                                             np.load('./data/SA/electronics/lexicon-labeled.npy'),\n",
    "                                                             np.load('./data/SA/kitchen/lexicon-labeled.npy')), \n",
    "                                                             axis=1))\n",
    "\n",
    "np.save('./data/SA/all/lexicon-unlabeled.npy', np.concatenate((np.load('./data/SA/books/lexicon-unlabeled.npy'),\n",
    "                                                             np.load('./data/SA/dvd/lexicon-unlabeled.npy'),\n",
    "                                                             np.load('./data/SA/electronics/lexicon-unlabeled.npy'),\n",
    "                                                             np.load('./data/SA/kitchen/lexicon-unlabeled.npy')), \n",
    "                                                             axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_coeffs = []\n",
    "parameters = {\n",
    "    'n_estimators': scipy.stats.uniform(loc=1, scale = 999),\n",
    "    'max_features': ('auto', 'sqrt', 'log2'),\n",
    "    'criterion': ('gini', 'entropy'),\n",
    "    'max_depth': scipy.stats,uniform(loc=1, scale = 999),\n",
    "    'min_leaf_nodes:' scipye.stats.uniform(loc=1, scale=999)\n",
    "}\n",
    "scores = ['precision', 'recall']\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_evaluate(classifier, dataset, feature):\n",
    "    \"\"\" Trains and evaluates specified classifier\n",
    "    \n",
    "    Args:\n",
    "        classifier (str): initials of classifier\n",
    "        dataset (str): category to be trained on\n",
    "        feature (str): file to use as training data\n",
    "        \n",
    "    Returns:\n",
    "        'pandas.dataframe': Dataframe containing metrics for each classifier    \n",
    "    \"\"\"\n",
    "    \n",
    "    if feature == 'bow':\n",
    "        item = ''\n",
    "    elif feature == 'bool-bow':\n",
    "        item = 'bool-'\n",
    "    else:\n",
    "        item = 'lexicon-'\n",
    "    path = './data/SA/' + dataset + '/' + item + 'labeled.npy'\n",
    "    data = np.transpose(np.load(path))\n",
    "    X = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.8, random_state=15)\n",
    "    if classifier == 'NB':\n",
    "        clf = GaussianNB()\n",
    "    elif classifier == 'LR':\n",
    "        clf = LogisticRegression(random_state=0, max_iter=500)\n",
    "    elif classifier == 'DT':\n",
    "        clf = DecisionTreeClassifier(random_state=0)\n",
    "    elif classifier == 'RF':\n",
    "        clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    if classifier == 'LR':\n",
    "        LR_coeffs.append(clf.coef_)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "    precision = metrics.precision_score(y_val, y_pred)\n",
    "    recall = metrics.recall_score(y_val, y_pred)\n",
    "    f1_score = metrics.f1_score(y_val, y_pred)\n",
    "    metrics_data = {'dataset': [dataset], 'classifier': [classifier], 'model':[feature],\n",
    "        'accuracy': [accuracy], 'precision':[precision], 'recall':[recall], 'f1_score': [f1_score]}\n",
    "    df = pd.DataFrame(data = metrics_data)\n",
    "    df.index = [dataset + ' ' + classifier + ' ' + feature]\n",
    "    return df\n",
    "\n",
    "def test_rf_hyperparameters(dataset, feature):\n",
    "    \"\"\" Testing hyperpaarameters for Random Forest classifier\n",
    "    Args:\n",
    "        dataset (str): dataset of category to use\n",
    "        feature (str): feature to use\n",
    "    \n",
    "    Returns:\n",
    "        list: best classifier for precision and recall\n",
    "    \"\"\"\n",
    "    \n",
    "    if feature == 'bow':\n",
    "        item = ''\n",
    "    elif feature == 'bool-bow':\n",
    "        item = 'bool-'\n",
    "    else:\n",
    "        item = 'lexicon-'\n",
    "    path = './data/SA/' + dataset + '/' + item + 'labeled.npy'\n",
    "    data = np.transpose(np.load(path))\n",
    "    X = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    df = pd.DataFrame()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.8, random_state=15)\n",
    "    clfs = []\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "        clf = RandomizedSearchCV(RandomForestClassifier(random_state=0), parameters, scoring='%s_macro' % score, n_jobs=9)\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_val, clf.predict(X_val)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "        clfs.append(clf)\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excecutes train_validate_evaluate for each feature, dataset and classifier\n",
    "df = pd.DataFrame()\n",
    "for classifier in classifiers:\n",
    "    for dataset in datasets:\n",
    "        for feature in features:\n",
    "            df = pd.concat([df, train_validate_evaluate(classifier, dataset, feature)], axis=0)\n",
    "df.to_latex('SA-df.txt', float_format=\"%.2f\", lontable=True, \n",
    "            caption='Análisis de sentimientos (resultados de modelos)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('classifier').mean().plot.bar(figsize=(12,8), rot=48)\n",
    "plt.title('Comparación de clasificadores', fontsize=20)\n",
    "plt.xlabel('Clasificador', fontsize=15)\n",
    "plt.ylabel('Porcentaje', fontsize=15)\n",
    "plt.grid()\n",
    "plt.savefig('./results/classifier_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('model').mean().plot.bar(figsize=(12,8), rot=48)\n",
    "plt.title('Comparación de modelos', fontsize=20)\n",
    "plt.xlabel('Modelo', fontsize=15)\n",
    "plt.ylabel('Porcentaje', fontsize=15)\n",
    "plt.grid()\n",
    "plt.savefig('./results/model_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('dataset').mean().plot.bar(figsize=(12,8), rot=48)\n",
    "plt.title('Comparación de datasets', fontsize=20)\n",
    "plt.xlabel('Categoría', fontsize=15)\n",
    "plt.ylabel('Porcentaje', fontsize=15)\n",
    "plt.grid()\n",
    "plt.savefig('./results/datasets_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs_all_b = test_rf_hyperparameters('all', 'bool-bow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs_all = test_rf_hyperparameters('all', 'bow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs_all_l = test_rf_hyperparameters('all', 'lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clfs_all_b[0]\n",
    "s = (clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))/max(clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))\n",
    "plt.scatter(clf.cv_results_['param_n_estimators'],\n",
    "            clf.cv_results_['param_max_features'], \n",
    "            s = s*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clfs_all_b[1]\n",
    "s = (clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))/max(clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))\n",
    "plt.scatter(clf.cv_results_['param_n_estimators'],\n",
    "            clf.cv_results_['param_max_features'], \n",
    "            s = s*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clfs_all[0]\n",
    "s = (clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))/max(clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))\n",
    "plt.scatter(clf.cv_results_['param_n_estimators'],\n",
    "            clf.cv_results_['param_max_features'], \n",
    "            s = s*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clfs_all[1]\n",
    "s = (clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))/max(clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))\n",
    "plt.scatter(clf.cv_results_['param_n_estimators'],\n",
    "            clf.cv_results_['param_max_features'], \n",
    "            s = s*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clfs_all_l[0]\n",
    "s = (clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))/max(clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))\n",
    "plt.scatter(clf.cv_results_['param_n_estimators'],\n",
    "            clf.cv_results_['param_max_features'], \n",
    "            s = s*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clfs_all_l[1]\n",
    "s = (clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))/max(clf.cv_results_['mean_test_score']-min(clf.cv_results_['mean_test_score']))\n",
    "plt.scatter(clf.cv_results_['param_n_estimators'],\n",
    "            clf.cv_results_['param_max_features'], \n",
    "            s = s*100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW02_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
