{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "breathing-shopping",
   "metadata": {},
   "source": [
    "# HW02 - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wanted-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "from smart_open import smart_open\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "universal-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['books', 'dvd', 'electronics', 'kitchen']\n",
    "files = ['positive', 'negative', 'unlabeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "strong-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_category_dataset(category):\n",
    "    \"\"\" Creates and saves dataset of specified category.\n",
    "    \n",
    "    Args:\n",
    "        category (str): category from which to build de dataset.\n",
    "    \n",
    "    Returns:\n",
    "        (list): contains pandas.core.frame.DataFrame. one with labeled data and one with unlabeled data.\n",
    "                Each df contains text, tag, bow, boolean bow and lexicon features.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        with open('./data/SA/' + category + '/' + file + '.review', encoding = 'ISO-8859-1') as fp:\n",
    "            soup = BeautifulSoup(fp, \"html.parser\")\n",
    "        reviews = soup.find_all(\"review_text\")\n",
    "        text = []\n",
    "        tag = []\n",
    "        for review in reviews:\n",
    "            text.append(review.text.strip('\\n'))\n",
    "            if file in ['positive', 'negative']:\n",
    "                tag.append(float(1) if file == 'positive' else float(0))\n",
    "                d = {'text': text, 'tag': tag}\n",
    "            else:\n",
    "                d = {'text': text}\n",
    "        dfs.append(pd.DataFrame(data = d))\n",
    "    df = pd.concat([dfs[0], dfs[1]], axis=0)\n",
    "    df_unlabeled = dfs[2]\n",
    "    p = PorterStemmer()\n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "    docDict = []\n",
    "    for doc in df['text']:\n",
    "        docDict.append(process(p, tokenizer, doc))\n",
    "    dictionary = corpora.Dictionary(docDict)\n",
    "    df['bow'] = df.apply(bow_model, axis=1, args=['not-bool', dictionary, p, tokenizer])\n",
    "    df_unlabeled['bow'] = df_unlabeled.apply(bow_model, axis=1, args=['not-bool', dictionary, p, tokenizer])\n",
    "    df['bool-bow'] = df.apply(bow_model, axis=1, args=['bool', dictionary, p, tokenizer])\n",
    "    df_unlabeled['bool-bow'] = df_unlabeled.apply(bow_model, axis=1, args=['bool', dictionary, p, tokenizer])\n",
    "    df.to_pickle('./data/SA/' + category + '/labeled.csv')\n",
    "    df.to_pickle('./data/SA/' + category + '/unlabeled.csv')\n",
    "    return [df, df_unlabeled]\n",
    "        \n",
    "def process(p, tokenizer, text):\n",
    "    \"\"\" Applies standard pre-processing to given text.\n",
    "\n",
    "    Args:\n",
    "        p (gensim.parsing.porter.PorterStemmer): stemmer object.\n",
    "        tokenizer (nltk.tokenize.regexp.RegexpTokenizer): tokenizr object.\n",
    "        text (str): text to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        list: preprocessed text.\n",
    "    \"\"\"\n",
    "    doc_nor = text.lower()\n",
    "    doc_sw = remove_stopwords(doc_nor)\n",
    "    doc_stem = p.stem_sentence(doc_sw)\n",
    "    return tokenizer.tokenize(doc_stem)\n",
    "\n",
    "def bow_model(param, boolean, dictionary, p, tokenizer):\n",
    "    \"\"\" Returns bow and boolean bow \n",
    "        Args:\n",
    "            param (<class 'pandas.core.series.Series'>): Series from pandas.DataFrame with tag information\n",
    "\n",
    "        Returns:\n",
    "        list: Numbers of relevant documents\n",
    "    \"\"\"\n",
    "    unordered_bow = dictionary.doc2bow(process(p, tokenizer, param.text))\n",
    "    doc_bow = np.zeros(len(dictionary), dtype=np.bool_ if boolean == 'bool' else np.float16)\n",
    "    for pair in unordered_bow:\n",
    "        doc_bow[pair[0]] = True if boolean == 'bool' else float(pair[1])\n",
    "    return np.array(doc_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entertaining-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "[df, df_unlabeled] = create_category_dataset('books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "peaceful-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "[df, df_unlabeled] = create_category_dataset('electronics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "raised-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "[df, df_unlabeled] = create_category_dataset('dvd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "attractive-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "[df, df_unlabeled] = create_category_dataset('kitchen')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
