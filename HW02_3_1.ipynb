{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "breathing-shopping",
   "metadata": {},
   "source": [
    "# HW02 - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wanted-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "from smart_open import smart_open\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "strong-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_category_dataset(categories):\n",
    "    \"\"\" Creates and saves dataset of specified category.\n",
    "    \n",
    "    Args:\n",
    "        category (str): category from which to build de dataset.\n",
    "    \n",
    "    Returns:\n",
    "        (list): contains pandas.core.frame.DataFrame. one with labeled data and one with unlabeled data.\n",
    "                Each df contains text, tag, bow, boolean bow and lexicon features.\n",
    "    \"\"\"\n",
    "    files = ['positive', 'negative', 'unlabeled']\n",
    "    if categories == 'all':\n",
    "        category = ['books', 'dvd', 'electronics', 'kitchen']\n",
    "        os.remove('./data/SA/all/labeled.csv')\n",
    "        os.remove('./data/SA/all/unlabeled.csv')\n",
    "    else:\n",
    "        category = [categories]\n",
    "        os.remove('./data/SA/'+categories+'/labeled.csv')\n",
    "        os.remove('./data/SA/'+categories+'/unlabeled.csv')\n",
    "    for file in files:\n",
    "        for category_instance in category:\n",
    "            df = pd.DataFrame()\n",
    "            with open('./data/SA/' + category_instance + '/' + file + '.review', encoding = 'ISO-8859-1') as fp:\n",
    "                soup = BeautifulSoup(fp, \"html.parser\")\n",
    "            reviews = soup.find_all('review_text')\n",
    "            for review in reviews:\n",
    "                if file == 'unlabeled':\n",
    "                    d = {'text': [review.text.strip('\\n')]}\n",
    "                else:\n",
    "                    tag = float(1) if file == 'positive' else float(0)\n",
    "                    d = {'text': [review.text.strip('\\n')], 'tag': [tag]}\n",
    "                df1 = pd.DataFrame(data=d)\n",
    "                df = pd.concat([df,df1], axis=0)\n",
    "            try:\n",
    "                if file == 'unlabeled':\n",
    "                    df_last = pd.read_csv('./data/SA/'+categories+'/unlabeled.csv', index_col=0)\n",
    "                    df_last = pd.concat([df_last, df], axis=0)\n",
    "                    df_last.to_csv('./data/SA/'+categories+'/unlabeled.csv')\n",
    "                else:\n",
    "                    df_last = pd.read_csv('./data/SA/'+categories+'/labeled.csv', index_col=0)\n",
    "                    df_last = pd.concat([df_last, df], axis=0)\n",
    "                    df_last.to_csv('./data/SA/'+categories+'/labeled.csv')\n",
    "            except:\n",
    "                if file == 'unlabeled':\n",
    "                    df.to_csv('./data/SA/'+categories+'/unlabeled.csv')\n",
    "                else:\n",
    "                    df.to_csv('./data/SA/'+categories+'/labeled.csv')\n",
    "        \n",
    "def process(p, tokenizer, text):\n",
    "    \"\"\" Applies standard pre-processing to given text.\n",
    "\n",
    "    Args:\n",
    "        p (gensim.parsing.porter.PorterStemmer): stemmer object.\n",
    "        tokenizer (nltk.tokenize.regexp.RegexpTokenizer): tokenizr object.\n",
    "        text (str): text to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        list: preprocessed text.\n",
    "    \"\"\"\n",
    "    doc_nor = text.lower()\n",
    "    doc_sw = remove_stopwords(doc_nor)\n",
    "    doc_stem = p.stem_sentence(doc_sw)\n",
    "    return tokenizer.tokenize(doc_stem)\n",
    "\n",
    "def bow_model(param, boolean, dictionary, p, tokenizer):\n",
    "    \"\"\" Returns bow and boolean bow \n",
    "        Args:\n",
    "            param (<class 'pandas.core.series.Series'>): Series from pandas.DataFrame with tag information\n",
    "\n",
    "        Returns:\n",
    "            list: Numbers of relevant documents\n",
    "    \"\"\"\n",
    "    unordered_bow = dictionary.doc2bow(process(p, tokenizer, param.text))\n",
    "    doc_bow = np.zeros(len(dictionary), dtype=np.bool_ if boolean == 'bool' else np.float16)\n",
    "    for pair in unordered_bow:\n",
    "        doc_bow[pair[0]] = True if boolean == 'bool' else float(pair[1])\n",
    "    return np.array(doc_bow)\n",
    "\n",
    "def process_df(path_to_df):\n",
    "    df = pd.read_csv(path_to_df, index_col=0)\n",
    "    p = PorterStemmer()\n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "    docDict = []\n",
    "    for doc in df['text']:\n",
    "        docDict.append(process(p, tokenizer, doc))\n",
    "    dictionary = corpora.Dictionary(docDict)\n",
    "    df['bow'] = df.apply(bow_model, axis=1, args=['not-bool', dictionary, p, tokenizer])\n",
    "    df['bool-bow'] = df.apply(bow_model, axis=1, args=['bool', dictionary, p, tokenizer])\n",
    "    df.to_pickle(path_to_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-divorce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for cat in tqdm(['books', 'electronics', 'dvd', 'kitchen', 'all']):\n",
    "    create_category_dataset(cat)\n",
    "path_list = ['./data/SA/books/labeled.csv', './data/SA/books/unlabeled.csv', './data/SA/dvd/labeled.csv',\n",
    "             './data/SA/dvd/unlabeled.csv', './data/SA/kitchen/labeled.csv', './data/SA/kitchen/unlabeled.csv',\n",
    "             './data/SA/electronics/labeled.csv', './data/SA/electronics/unlabeled.csv', \n",
    "             './data/SA/all/labeled.csv', './data/SA/all/unlabeled.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_path in tqdm(path_list):\n",
    "    try:\n",
    "        process_df(df_path)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_path in path_list:\n",
    "    try:\n",
    "        df = pd.read_csv(df_path, index_col=0)\n",
    "        print(df.head())\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
